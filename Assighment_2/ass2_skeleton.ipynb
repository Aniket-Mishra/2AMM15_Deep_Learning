{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wv9q_pcGshE"
      },
      "source": [
        "# Assignment 2 2AMM10 2023-2024\n",
        "\n",
        "## Group: [Fill in your group name]\n",
        "### Member 1: [Fill in your name]\n",
        "### Member 2: [Fill in your name]\n",
        "### Member 3: [Fill in your name]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQzvuDWw_Eyw"
      },
      "source": [
        "We need to install some specific libraries. The cell below installs torch_geometric for torch 2.6.0+cu124. In case the current version of torch is different, check [here](https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html) to see which versions (of both libraries) you should install. You might also need to install an old version of torch from [here](https://pytorch.org/get-started/previous-versions/)\n",
        "\n",
        "**Note:** Do not install pyg_lib from the optional dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "ibC2lMHfD67H"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: torch\n",
            "Version: 2.6.0\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3-Clause\n",
            "Location: /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-cusparselt-cu12, nvidia-nccl-cu12, nvidia-nvjitlink-cu12, nvidia-nvtx-cu12, setuptools, sympy, triton, typing-extensions\n",
            "Required-by: openml-pytorch, pytorch-lightning, torchmetrics, torchvision\n"
          ]
        }
      ],
      "source": [
        "!pip show torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "8qrPQFNe_AJu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rdkit in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (2025.3.3)\n",
            "Requirement already satisfied: numpy in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from rdkit) (11.1.0)\n",
            "Requirement already satisfied: torch_geometric in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from torch_geometric) (3.11.14)\n",
            "Requirement already satisfied: fsspec in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from torch_geometric) (2025.2.0)\n",
            "Requirement already satisfied: jinja2 in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from torch_geometric) (7.0.0)\n",
            "Requirement already satisfied: pyparsing in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from aiohttp->torch_geometric) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.0 in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch_geometric) (3.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Requirement already satisfied: torch_scatter in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (2.1.2+pt26cu124)\n",
            "Requirement already satisfied: torch_sparse in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (0.6.18+pt26cu124)\n",
            "Requirement already satisfied: torch_cluster in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (1.6.3+pt26cu124)\n",
            "Requirement already satisfied: torch_spline_conv in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (1.2.2+pt26cu124)\n",
            "Requirement already satisfied: scipy in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from torch_sparse) (1.12.0)\n",
            "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in /home/ubuntu/miniconda3/envs/dl/lib/python3.12/site-packages (from scipy->torch_sparse) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit\n",
        "!pip install torch_geometric\n",
        "!pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "WVL2eo0g_Iuv"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw, AllChem\n",
        "from rdkit import RDLogger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# More imports\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "H8rvaK56_iQ7"
      },
      "outputs": [],
      "source": [
        "with open('ass2_data/pos_data.pkl', 'rb') as f:\n",
        "    pos_data = pickle.load(f)\n",
        "\n",
        "with open('ass2_data/type_data.pkl', 'rb') as f:\n",
        "    type_data = pickle.load(f)\n",
        "\n",
        "with open('ass2_data/smiles.pkl', 'rb') as f:\n",
        "    smiles_data = pickle.load(f)\n",
        "\n",
        "data_split = np.load('ass2_data/data_split.npz')\n",
        "\n",
        "train_idxes = data_split['train_idx']\n",
        "test_idxes = data_split['test_idx']\n",
        "\n",
        "formation_energy = np.load('ass2_data/formation_energy.npz')\n",
        "\n",
        "fe = formation_energy['y'] # normalized formation energy\n",
        "mu = formation_energy['mu']\n",
        "std = formation_energy['sigma']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "DIsGRQcxA_4Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of data\n",
            "pos_data: 129012, type_data: 129012, smiles: 129012\n",
            "Idxes\n",
            "train: 119012, test: 10000, sum: 129012\n"
          ]
        }
      ],
      "source": [
        "# shapes of lists\n",
        "print(\"Length of data\")\n",
        "print(f\"pos_data: {len(pos_data)}, type_data: {len(type_data)}, smiles: {len(smiles_data)}\")\n",
        "print(\"Idxes\")\n",
        "print(f\"train: {len(train_idxes)}, test: {len(test_idxes)}, sum: {len(train_idxes) + len(test_idxes)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "bVDJF7I3BFa2"
      },
      "outputs": [],
      "source": [
        "def at_number_to_atom_name(at_number):\n",
        "    if at_number == 6:\n",
        "        return 'C'\n",
        "    elif at_number == 1:\n",
        "        return 'H'\n",
        "    elif at_number == 7:\n",
        "        return 'N'\n",
        "    elif at_number == 8:\n",
        "        return 'O'\n",
        "    elif at_number == 9:\n",
        "        return 'F'\n",
        "    elif at_number == 16:\n",
        "        return 'S'\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "def inspect_structure(idx):\n",
        "    smile = smiles_data[idx]\n",
        "    pos = pos_data[idx]\n",
        "    typ = type_data[idx]\n",
        "\n",
        "    header = f\"{'Atom':^5}│{'Number':^6}│{'x':^10}│{'y':^10}│{'z':^10}\"\n",
        "    line   = \"─────┼──────┼──────────┼──────────┼──────────\"\n",
        "    print(header)\n",
        "    print(line)\n",
        "\n",
        "    for atom_num, (x, y, z) in zip(typ, pos):\n",
        "        atom_sym = at_number_to_atom_name(atom_num)\n",
        "        print(f\"{atom_sym:^5}│{atom_num:^6}│{x:>10.3f}│{y:>10.3f}│{z:>10.3f}\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(f'SMILE: {smile}')\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(f'Formation Energy: {fe[idx]*std + mu:.3f}')\n",
        "    print(f'Formation Energy (normalized): {fe[idx]:.5f}')\n",
        "    mol = Chem.MolFromSmiles(smile)\n",
        "    if mol:\n",
        "        # RDKit prefers 2‑D coordinates for nice depictions\n",
        "        Chem.AllChem.Compute2DCoords(mol)\n",
        "        img = Draw.MolToImage(mol, size=(300, 300))\n",
        "\n",
        "        # Display with matplotlib (works both in notebooks and scripts)\n",
        "        plt.figure(figsize=(3, 3))\n",
        "        plt.axis('off')\n",
        "        plt.imshow(img)\n",
        "        plt.show()\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "K1rs7hhCC4oq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Atom │Number│    x     │    y     │    z     \n",
            "─────┼──────┼──────────┼──────────┼──────────\n",
            "  C  │  6   │    -0.013│     1.086│     0.008\n",
            "  H  │  1   │     0.002│    -0.006│     0.002\n",
            "  H  │  1   │     1.012│     1.464│     0.000\n",
            "  H  │  1   │    -0.541│     1.447│    -0.877\n",
            "  H  │  1   │    -0.524│     1.438│     0.906\n",
            "\n",
            "\n",
            "SMILE: C\n",
            "\n",
            "\n",
            "Formation Energy: -17.172\n",
            "Formation Energy (normalized): 5.72327\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAACf9JREFUeJzt3EtsVGUDxvHnzNDpUFpoKU1TSpWLt8hFo9wMaQLeIisXLDAxMUYjMZGF4AJdyQJjDEKaSFIWhMCGBCOJgBJQQ6IRFkYXSg0Gk4KiJdrCVEaGMkPndUE64QvIN8Whc+D5/zYk9EzPezr5z7m9c6IQQhCAO1qi2gMAcOsROmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AED46o9AJSnUChoYGBAf//9ty5fvqz6+no1Njaqvr5eURRds3wIQfl8XsViUVEUKZVKKZEo73P90qVLKhaLkqRUKqVkMlnRbcHYi0IIodqDwLVG3pbTp09r7969OnLkiPr6+jQ0NKTh4WGl02lNnjxZCxYs0IoVK/Tggw9KUin6gYEBvffee+rp6dHUqVO1Zs0azZkzp6x1r127VsePH1c6ndaGDRs0e/bsW7ORGDsBsVMsFsNff/0VNm/eHDo6OkJtbW2IoihIClEUhUQiESQFSSGVSoWWlpbw7rvvhkwmE4rFYgghhNOnT4fOzs4gKdxzzz3hyy+/LHv9jz32WJAUJkyYEL766qtbtZkYQxy6x0wIQWfOnNE777yj7du3a2hoSMlkUrNmzdJ9992nlpYWpdNpZTIZnTp1SsePH1d/f782bNigTCajt956S42NjdXeDMQMocfM0NCQtm3bpp07d2poaEgNDQ1auXKlnn/+ec2bN09NTU2Srpyz9/b26vDhw9q4caP6+vrU39+vQqFQ5S1AHBF6jIQQdOzYMXV1denChQuqqanRq6++WtpLX33RLZVK6YEHHtDMmTM1Z84cHTx4UKtXr1Zzc3MVtwBxRegxEkJQd3e3MpmMJGnRokV6++23VVdXd90r69KV4Ds7O9XZ2SlJ/7ocvBF6jAwMDOizzz6TJCUSCb3++us3jHwEceP/YcJMjPzwww86f/68JGnWrFl69NFHqzwi3CnYo8fI999/r3w+L0maPXu2GhoaKra3DiGUJsHAD6HHSH9/fynGadOmqba2tiK/N5PJaPfu3frmm2/KWr6vr68i60V8EHqMnD9/vjQjrr6+vmJTT8+ePavu7u6K/C7cngg9RorFYin0cuellyOZTGrixIlKpVJlLX/u3Dnux99hCD1GGhoalEgkVCwWdeHChYqdU3d0dGjTpk1atGhRWcs/++yz+u677yqybsQDocdIU1NTaU9eyVlu48aN05QpU9Te3l7W8uXu+XH74PZajNx///0aN+7KZ++JEyeUy+VKh/LAf0HoMfLII49o/PjxkqRjx47p5MmTVR4R7hSEHiMdHR2aP3++pCsPf9i2bZuGh4erPCrcCQg9RpLJpF555ZXSefrHH3+sTz75RCGEGx7Cj/y8mof5V4+h2mPBtbgYFzOPP/64nnvuOe3evVuDg4Nas2aNstmsnnnmGTU3N//PbbcQgnK5nP7880+dOHFC8+bNU1tb25iPOYSgH3/8Ud9++62Gh4fV2tqqJ598Uul0eszHgusj9BiJokiNjY1644039Ntvv+nIkSM6deqUXnvtNT399NNatmyZpk2bprq6OuXzef3xxx/q6enR4cOH9fvvv+uDDz7QypUrx/xLLmfOnNG6dev0+eefK4SghQsXavHixYQeI4QeM1EU6aGHHlJXV5fWr1+v/fv3K5vNas+ePdq3b5+ampqUTqdVKBQ0ODioixcvSrpyS+znn39WoVAY09tj+XxeH374ob7++mstX75cR48eHbN1o3yco8dQMpnUww8/rB07dmjXrl1aunSpWltbNX78eOVyOZ09e1bZbFa1tbVqbW3V8uXLtWPHDq1evVo1NTWSrsysmzhxopqbm9XU1FT6/3JMmjRJzc3Nmjx58g1fN/KgjK1bt6q9vV3r1q0r3R5EvPAU2JgbubD166+/6qefftK5c+d06dIl1dfXq62tTffee69aWlpKh+sj/xYKBfX19SmXyymVSqmtrU11dXVlrfOXX35RLpdTIpFQR0fHv74um83qpZde0hdffKHu7m7Nnz9fnZ2dmjlzpvbu3aspU6ZU5o+A/4yP35iLokhRFGn69OmaPn162a+rqanR3XfffVPrLPd1H330kQ4cOKAVK1boiSeeUDabvan14dbj0B2jFkJQT0+PNm3apKlTp2rVqlXsvWOO0DFqg4OD6urqUm9vr15++WUtWbKEx1nFHKFjVIaHh3Xo0CHt27dPCxYs0KpVq4j8NsA5OkZlYGBA77//vgqFgt58801NmjSpNE336q/VFotFFYvFin6vHjePq+4Yla6uLq1du1aSlE6nr5mpd/HiRUVRpAkTJuiFF17Qli1bqjVUXIU9OkZlxowZevHFF6/7s2w2q08//VQNDQ166qmnSl/QQfWxR8eoXL58+V+ffHPy5EktXbpUM2bM0J49e9TS0sIEmpjgXcCo3CjckVl0URSppqaGyGOEdwIVk0qlNHfuXLW3txN5zHDojorJ5/Pq7e1VKpXSXXfdRewxQuiAAW5yAgYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTBA6ICBfwC9hRQTICOM3AAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# methane\n",
        "# Note how methane has a relatively high formation energy (compared to QM9)\n",
        "# This correlates with lower thermodynamic stability and higher reactivity\n",
        "# For example, methane readily burns in oxygen (CH₄ + 2O₂ → CO₂ + 2H₂O)\n",
        "inspect_structure(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "vo8hYLuQCeBR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Atom │Number│    x     │    y     │    z     \n",
            "─────┼──────┼──────────┼──────────┼──────────\n",
            "  C  │  6   │    -0.752│     1.247│    -0.023\n",
            "  C  │  6   │     0.200│     0.055│     0.014\n",
            "  C  │  6   │     1.194│    -0.002│    -1.199\n",
            "  C  │  6   │     2.363│    -0.718│    -0.601\n",
            "  N  │  7   │     3.432│    -1.340│    -0.994\n",
            "  O  │  8   │     4.044│    -1.743│     0.181\n",
            "  N  │  7   │     3.325│    -1.355│     1.299\n",
            "  C  │  6   │     2.297│    -0.727│     0.817\n",
            "  C  │  6   │     1.077│    -0.018│     1.313\n",
            "  H  │  1   │    -0.198│     2.192│     0.009\n",
            "  H  │  1   │    -1.356│     1.243│    -0.936\n",
            "  H  │  1   │    -1.438│     1.232│     0.830\n",
            "  H  │  1   │    -0.390│    -0.869│    -0.020\n",
            "  H  │  1   │     0.763│    -0.499│    -2.071\n",
            "  H  │  1   │     1.485│     1.010│    -1.511\n",
            "  H  │  1   │     1.337│     0.989│     1.664\n",
            "  H  │  1   │     0.567│    -0.526│     2.135\n",
            "\n",
            "\n",
            "SMILE: CC1Cc2nonc2C1\n",
            "\n",
            "\n",
            "Formation Energy: -72.633\n",
            "Formation Energy (normalized): 0.34440\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# random structure\n",
        "inspect_structure(np.random.choice(range(len(smiles_data))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Determine system settings (to optimize training parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System Info\n",
            "\n",
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n",
            "Device: NVIDIA GeForce RTX 3060 Ti\n"
          ]
        }
      ],
      "source": [
        "print(\"System Info\\n\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"Running on CPU.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setting variables\n",
        "skip_training = True\n",
        "MODEL_PATH = \"smiles_model_task3.pth\"\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "def tokenize_smiles(smiles):\n",
        "    return list(smiles)\n",
        "\n",
        "# Build vocabulary from a list of SMILES strings\n",
        "def build_vocab(smiles_list):\n",
        "    special_tokens = ['<pad>', '<sos>', '<eos>']\n",
        "    all_chars = sorted(set(''.join(smiles_list)))\n",
        "    itos = special_tokens + all_chars\n",
        "    stoi = {s: i for i, s in enumerate(itos)}\n",
        "    return stoi, itos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SmilesDataset(Dataset):\n",
        "    def __init__(self, smiles_list, stoi, max_len=120):\n",
        "        self.stoi = stoi\n",
        "        self.itos = {i: s for s, i in stoi.items()}\n",
        "        self.max_len = max_len\n",
        "        self.pad_idx = self.stoi['<pad>']\n",
        "        self.sos_idx = self.stoi['<sos>']\n",
        "        self.eos_idx = self.stoi['<eos>']\n",
        "        self.data = [self.encode(s) for s in smiles_list]\n",
        "\n",
        "    def encode(self, s):\n",
        "        tokens = ['<sos>'] + tokenize_smiles(s) + ['<eos>']\n",
        "        ids = [self.stoi[c] for c in tokens]\n",
        "        if len(ids) < self.max_len:\n",
        "            ids += [self.pad_idx] * (self.max_len - len(ids))\n",
        "        return ids[:self.max_len]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = torch.tensor(self.data[idx], dtype=torch.long)\n",
        "        return seq[:-1], seq[1:]  # input, target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76MeHNQ_Gd9t"
      },
      "source": [
        "## Task 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lv736iffCez4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0zvKnpLGf9v"
      },
      "source": [
        "## Task 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AC1KICrZGgkY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mIuOY4BGxqU"
      },
      "source": [
        "## Task 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "z_NgxsO3GxEE"
      },
      "outputs": [],
      "source": [
        "def is_valid_smiles(smiles):\n",
        "    if smiles is None:\n",
        "        return False\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        return mol is not None\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def canonicalize(smiles):\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol:\n",
        "            return Chem.MolToSmiles(mol, canonical=True)\n",
        "        return 'None'\n",
        "    except:\n",
        "        return 'None'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "SN_jGgOwG4kK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('COO', 'COO')"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "canonicalize(\"COO\"), canonicalize(\"O(C)O\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "-bhjYhYrHCuQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(True, True, False)"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "is_valid_smiles(\"COO\"), is_valid_smiles(\"O(C)O\"), is_valid_smiles(\"C##\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "0_YgzDpMH-Vl"
      },
      "outputs": [],
      "source": [
        "class SmilesLSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256, num_layers=2, dropout=0.1, pad_idx=0):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, \n",
        "                            batch_first=True, dropout=dropout)\n",
        "        self.output = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        embedded = self.embedding(x)\n",
        "        out, hidden = self.lstm(embedded, hidden)\n",
        "        logits = self.output(out)\n",
        "        return logits, hidden\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, train_dataset, stoi, epochs=10, batch_size=64, lr=1e-3,\n",
        "                device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "\n",
        "    batch_size = 256 if torch.cuda.is_available() else 64\n",
        "    pad_idx = stoi['<pad>']\n",
        "    model = model.to(device)\n",
        "\n",
        "    if skip_training:\n",
        "      print(\"Skipping training. Loading saved model weights...\")\n",
        "      model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "      model = model.to(device)\n",
        "      return model\n",
        "\n",
        "    model.train()\n",
        "    loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        total_loss = 0.0\n",
        "        loop = tqdm(loader, desc=f\"Epoch {epoch}\")\n",
        "        for x, y in loop:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits, _ = model(x)\n",
        "\n",
        "            loss = loss_fn(logits.view(-1, logits.size(-1)), y.view(-1))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_loss = total_loss / len(loader)\n",
        "        print(f\"Epoch {epoch} completed. Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    torch.save(model.state_dict(), MODEL_PATH)\n",
        "    print(f\"Model saved to {MODEL_PATH}\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 465/465 [00:30<00:00, 15.08it/s, loss=0.619]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 completed. Avg Loss: 0.7804\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 465/465 [00:30<00:00, 15.29it/s, loss=0.586]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 completed. Avg Loss: 0.5952\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 465/465 [00:27<00:00, 16.97it/s, loss=0.565]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 completed. Avg Loss: 0.5672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 465/465 [00:29<00:00, 15.85it/s, loss=0.543]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 completed. Avg Loss: 0.5530\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 465/465 [00:34<00:00, 13.63it/s, loss=0.547]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 completed. Avg Loss: 0.5441\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 465/465 [00:29<00:00, 15.94it/s, loss=0.532]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 completed. Avg Loss: 0.5377\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 465/465 [00:31<00:00, 14.56it/s, loss=0.525]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 completed. Avg Loss: 0.5328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 465/465 [00:31<00:00, 14.97it/s, loss=0.528]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 completed. Avg Loss: 0.5290\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 465/465 [00:31<00:00, 14.83it/s, loss=0.525]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 completed. Avg Loss: 0.5256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 465/465 [00:30<00:00, 15.22it/s, loss=0.522]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 completed. Avg Loss: 0.5227\n",
            "Model saved to smiles_model.pth\n"
          ]
        }
      ],
      "source": [
        "train_smiles = [smiles_data[i] for i in train_idxes]\n",
        "stoi, itos = build_vocab(train_smiles)\n",
        "train_dataset = SmilesDataset(train_smiles, stoi, max_len=120)\n",
        "\n",
        "model = SmilesLSTMModel(\n",
        "    vocab_size=len(stoi),\n",
        "    embed_dim=256,\n",
        "    hidden_dim=512,\n",
        "    num_layers=2,\n",
        "    dropout=0.1,\n",
        "    pad_idx=stoi['<pad>']\n",
        ")\n",
        "\n",
        "model = train_model(model, train_dataset, stoi, epochs=10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sample_smiles(model, stoi, itos, max_length=120, temperature=1.0, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "    model.eval()\n",
        "    generated = []\n",
        "    sos_idx = stoi['<sos>']\n",
        "    eos_idx = stoi['<eos>']\n",
        "\n",
        "    with torch.no_grad():\n",
        "        input_seq = torch.tensor([[sos_idx]], dtype=torch.long).to(device)\n",
        "        hidden = None\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            logits, hidden = model(input_seq, hidden)\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            next_token = torch.multinomial(probs, num_samples=1)\n",
        "            next_idx = next_token.item()\n",
        "\n",
        "            if next_idx == eos_idx:\n",
        "                break\n",
        "\n",
        "            generated.append(itos[next_idx])\n",
        "            input_seq = next_token\n",
        "\n",
        "    return ''.join(generated)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_smiles_batch(model, stoi, itos, n=5000, temperature=1.0):\n",
        "    samples = []\n",
        "    for _ in tqdm(range(n), desc=\"Generating SMILES\"):\n",
        "        smi = sample_smiles(model, stoi, itos, temperature=temperature)\n",
        "        samples.append(smi)\n",
        "    return samples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_smiles(generated_smiles, train_smiles):\n",
        "    train_set = set([canonicalize(s) for s in train_smiles])\n",
        "    valid_smiles = []\n",
        "    canonical_valid = []\n",
        "\n",
        "    for smi in generated_smiles:\n",
        "        if is_valid_smiles(smi):\n",
        "            can = canonicalize(smi)\n",
        "            if can != 'None':\n",
        "                valid_smiles.append(smi)\n",
        "                canonical_valid.append(can)\n",
        "\n",
        "    total_generated = len(generated_smiles)\n",
        "    total_valid = len(valid_smiles)\n",
        "    unique_valid = len(set(canonical_valid))\n",
        "    novel_valid = len([s for s in set(canonical_valid) if s not in train_set])\n",
        "\n",
        "    return {\n",
        "        \"validity\": total_valid / total_generated * 100,\n",
        "        \"uniqueness\": unique_valid / total_valid * 100 if total_valid > 0 else 0,\n",
        "        \"novelty\": novel_valid / total_valid * 100 if total_valid > 0 else 0,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating SMILES: 100%|██████████| 5000/5000 [01:28<00:00, 56.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Results:\n",
            "Validity: 98.54%\n",
            "Uniqueness: 97.93%\n",
            "Novelty: 30.40%\n"
          ]
        }
      ],
      "source": [
        "samples = generate_smiles_batch(model, stoi, itos, n=5000, temperature=0.9)\n",
        "metrics = evaluate_smiles(samples, train_smiles)\n",
        "print(\"Evaluation Results:\")\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k.capitalize()}: {v:.2f}%\")\n",
        "\n",
        "with open(\"generated_smiles.txt\", \"w\") as f:\n",
        "    for smi in samples:\n",
        "        f.write(smi + \"\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
